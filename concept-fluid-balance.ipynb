{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# AmsterdamUMCdb Login & Connection Setup\n",
        "This notebook provides the basic setup to connect to the AmsterdamUMCdb on Google BigQuery.\n",
        "Fill in the form fields on the right and run the cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_setup_md"
      },
      "source": [
        "## 1. Project Configuration\n",
        "Enter your Google Cloud Project ID and the dataset details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "project_setup_code"
      },
      "outputs": [],
      "source": [
        "#@title Project Configuration { display-mode: \"form\" }\n",
        "\n",
        "PROJECT_ID = \"datathon-484308\" #@param {type:\"string\"}\n",
        "DATASET_PROJECT_ID = 'amsterdamumcdb' #@param {type:\"string\"}\n",
        "DATASET_ID = 'van_gogh_2026_datathon' #@param {type:\"string\"}\n",
        "LOCATION = 'eu' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Set environment variable for Google Cloud Project\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "\n",
        "print(f\"Project ID set to: {PROJECT_ID}\")\n",
        "print(f\"Dataset: {DATASET_PROJECT_ID}.{DATASET_ID} (Location: {LOCATION})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auth_md"
      },
      "source": [
        "## 2. Authentication\n",
        "Run this cell to authenticate your Google account. You will need to use the account that has access to AmsterdamUMCdb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auth_code"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate User { display-mode: \"form\" }\n",
        "auth.authenticate_user()\n",
        "print('Successfully authenticated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "client_setup_md"
      },
      "source": [
        "## 3. Initialize BigQuery Client\n",
        "This cell sets up the client and default configurations for querying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "client_setup_code"
      },
      "outputs": [],
      "source": [
        "#@title Initialize Client { display-mode: \"form\" }\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Default query job configuration\n",
        "def_config = bigquery.job.QueryJobConfig(default_dataset=f\"{DATASET_PROJECT_ID}.{DATASET_ID}\")\n",
        "\n",
        "# Create the BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID, location=LOCATION, default_query_job_config=def_config)\n",
        "\n",
        "# Enable data table display in Colab\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab.data_table import DataTable\n",
        "DataTable.max_columns = 50\n",
        "DataTable.max_rows = 20000\n",
        "\n",
        "print(\"BigQuery client initialized and ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Detailed Fluid Balance"
      ],
      "metadata": {
        "id": "RkK1SfoOv8im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing purposes: Single visit validation"
      ],
      "metadata": {
        "id": "eh4BsPajNGFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Single Visit Validator (Manual Check - Calendar Day)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# --- 1. PARAMETERS ---\n",
        "# Enter the Visit ID you want to audit (from the main result table)\n",
        "VISIT_ID = 34050 #@param {type:\"integer\"}\n",
        "\n",
        "# Client Setup\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset_ref = f\"{DATASET_PROJECT_ID}.{DATASET_ID}\"\n",
        "job_config = bigquery.QueryJobConfig(default_dataset=dataset_ref)\n",
        "\n",
        "# --- 2. CONFIGURATION (Must match main script) ---\n",
        "INPUT_IDS = [\n",
        "    3037253, # Intravascular\n",
        "    3010494, # Enteral\n",
        "    3006552  # Oral\n",
        "]\n",
        "\n",
        "OUTPUT_IDS = [\n",
        "    3014315, # Urine\n",
        "    3011087, # Stool\n",
        "    3026556, # Chest Tube\n",
        "    3018767, # Ventricle Drain\n",
        "    21491183, # GI Drain\n",
        "    3020433  # Misc\n",
        "]\n",
        "\n",
        "# Generate SQL lists\n",
        "input_sql_list = \", \".join(map(str, INPUT_IDS))\n",
        "output_sql_list = \", \".join(map(str, OUTPUT_IDS))\n",
        "all_ids_sql_list = \", \".join(map(str, INPUT_IDS + OUTPUT_IDS))\n",
        "\n",
        "# --- 3. FETCH RAW DATA ---\n",
        "print(f\"Fetching raw fluid measurements for Visit ID: {VISIT_ID}...\")\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "    m.measurement_datetime,\n",
        "    m.measurement_concept_id,\n",
        "    m.value_as_number\n",
        "FROM measurement m\n",
        "JOIN visit_occurrence v ON m.person_id = v.person_id\n",
        "WHERE v.visit_occurrence_id = {VISIT_ID}\n",
        "  AND m.measurement_concept_id IN ({all_ids_sql_list})\n",
        "  -- Get all data strictly within the visit window\n",
        "  AND m.measurement_datetime BETWEEN v.visit_start_datetime AND IFNULL(v.visit_end_datetime, CURRENT_TIMESTAMP())\n",
        "ORDER BY m.measurement_datetime\n",
        "\"\"\"\n",
        "\n",
        "df_raw = client.query(query, job_config=job_config).to_dataframe()\n",
        "\n",
        "if df_raw.empty:\n",
        "    print(f\"âŒ No fluid data found for Visit ID {VISIT_ID}.\")\n",
        "else:\n",
        "    # --- 4. PYTHON CALCULATION (Calendar Day Logic) ---\n",
        "    # Convert to datetime (Pandas handles BQ timestamps usually as UTC)\n",
        "    df_raw['measurement_datetime'] = pd.to_datetime(df_raw['measurement_datetime'])\n",
        "\n",
        "    # Check if data is timezone aware\n",
        "    is_tz_aware = df_raw['measurement_datetime'].dt.tz is not None\n",
        "\n",
        "    # Categorize\n",
        "    def get_category(cid):\n",
        "        if cid in INPUT_IDS: return 'Input'\n",
        "        if cid in OUTPUT_IDS: return 'Output'\n",
        "        return 'Unknown'\n",
        "\n",
        "    df_raw['Category'] = df_raw['measurement_concept_id'].apply(get_category)\n",
        "\n",
        "    # Logic: Simple Calendar Date\n",
        "    df_raw['Report_Date'] = df_raw['measurement_datetime'].dt.date\n",
        "\n",
        "    # --- 5. AGGREGATED TABLE ---\n",
        "    print(\"\\n--- 1. Aggregated Daily Balance (Calendar Day) ---\")\n",
        "    print(\"Compare this table with your BigQuery SQL results.\")\n",
        "\n",
        "    daily = df_raw.groupby(['Report_Date', 'Category'])['value_as_number'].sum().unstack(fill_value=0)\n",
        "\n",
        "    # Ensure columns exist\n",
        "    if 'Input' not in daily: daily['Input'] = 0\n",
        "    if 'Output' not in daily: daily['Output'] = 0\n",
        "\n",
        "    daily['Daily_Balance'] = daily['Input'] - daily['Output']\n",
        "    # Calculate Cumulative Balance\n",
        "    daily['Cumulative_Balance'] = daily['Daily_Balance'].cumsum()\n",
        "\n",
        "    display(daily.style.format(\"{:,.0f}\").background_gradient(cmap='RdBu', subset=['Daily_Balance']))\n",
        "\n",
        "    # --- 6. VISUALIZATION ---\n",
        "    print(\"\\n--- 2. Visualization: Cumulative Balance over Time ---\")\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Prepare flow for plotting\n",
        "    df_raw['Flow'] = df_raw.apply(lambda x: x['value_as_number'] if x['Category']=='Input' else -x['value_as_number'], axis=1)\n",
        "    df_raw['CumSum_Exact'] = df_raw['Flow'].cumsum()\n",
        "\n",
        "    # Plot Line\n",
        "    plt.plot(df_raw['measurement_datetime'], df_raw['CumSum_Exact'], label='Cumulative Balance', color='purple', linewidth=2)\n",
        "\n",
        "    # Mark Midnight (00:00) for every day involved\n",
        "    days = df_raw['measurement_datetime'].dt.date.unique()\n",
        "\n",
        "    # Get min timestamp for comparison\n",
        "    min_ts = df_raw['measurement_datetime'].min()\n",
        "\n",
        "    for day in days:\n",
        "        # Create timestamp for midnight\n",
        "        midnight = pd.Timestamp(day)\n",
        "\n",
        "        # FIX: Make midnight timezone-aware if the data is timezone-aware\n",
        "        if is_tz_aware:\n",
        "            midnight = midnight.tz_localize(df_raw['measurement_datetime'].dt.tz)\n",
        "\n",
        "        # Only plot if it falls within or after the start of data\n",
        "        if midnight >= min_ts:\n",
        "            plt.axvline(midnight, color='gray', linestyle='--', alpha=0.5)\n",
        "            plt.text(midnight, df_raw['CumSum_Exact'].min(), ' 00:00', fontsize=8, color='gray', rotation=90)\n",
        "\n",
        "    plt.title(f'Fluid Balance (Calendar Days) for Visit {VISIT_ID}')\n",
        "    plt.ylabel('Cumulative Volume (ml)')\n",
        "    plt.xlabel('Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
        "    plt.show()\n",
        "\n",
        "    # --- 7. RAW DATA SAMPLE ---\n",
        "    print(\"\\n--- 3. Raw Data Sample ---\")\n",
        "    display(df_raw[['measurement_datetime', 'Category', 'value_as_number', 'Report_Date']].head(5))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WkJiV31z2twL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script for extraction of daily fluid balances"
      ],
      "metadata": {
        "id": "48C-KNs1NLjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fluid Balance Extraction (Daily Aggregation)\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# --- 1. Client & Dataset Setup ---\n",
        "# Initialize BigQuery client using project and dataset variables defined globally\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset_ref = f\"{DATASET_PROJECT_ID}.{DATASET_ID}\"\n",
        "job_config = bigquery.QueryJobConfig(default_dataset=dataset_ref)\n",
        "\n",
        "print(f\"Fluid Balance: Client configured for dataset '{dataset_ref}'\")\n",
        "\n",
        "\n",
        "# Concept ID Configuration\n",
        "# Define which concepts constitute Input (Intake) vs. Output (Losses)\n",
        "INPUT_IDS = [\n",
        "    3037253, # Intravascular\n",
        "    3010494, # Enteral\n",
        "    3006552  # Oral\n",
        "]\n",
        "\n",
        "OUTPUT_IDS = [\n",
        "    3014315, # Urine\n",
        "    3011087, # Stool\n",
        "    3026556, # Chest Tube\n",
        "    3018767, # Ventricle Drain\n",
        "    21491183, # GI Drain\n",
        "    3020433  # Misc\n",
        "]\n",
        "\n",
        "# --- 3. Query Construction ---\n",
        "# Format lists for SQL IN clauses\n",
        "input_sql_list = \", \".join(map(str, INPUT_IDS))\n",
        "output_sql_list = \", \".join(map(str, OUTPUT_IDS))\n",
        "all_ids_sql_list = \", \".join(map(str, INPUT_IDS + OUTPUT_IDS))\n",
        "\n",
        "# --- 4. SQL Execution ---\n",
        "# Logic: Aggregates fluid data by Person, Visit, and Calendar Date.\n",
        "# Calculates Daily Balance (Input - Output) and Cumulative Balance per Visit.\n",
        "query_text = f\"\"\"\n",
        "WITH vlist AS (\n",
        "  -- Identify target cohort (ventilated patients)\n",
        "  SELECT DISTINCT person_id\n",
        "  FROM measurement m\n",
        "  JOIN concept c ON m.measurement_concept_id = c.concept_id\n",
        "  WHERE concept_name LIKE '%ventila%'\n",
        "),\n",
        "labeled_data AS (\n",
        "  SELECT\n",
        "    m.person_id,\n",
        "    v.visit_occurrence_id,\n",
        "    m.measurement_datetime,\n",
        "    m.value_as_number,\n",
        "    -- Extract Calendar Date from timestamp\n",
        "    DATE(m.measurement_datetime) as report_date,\n",
        "    -- Classify measurements based on configured IDs\n",
        "    CASE\n",
        "      WHEN m.measurement_concept_id IN ({input_sql_list}) THEN 'Input'\n",
        "      WHEN m.measurement_concept_id IN ({output_sql_list}) THEN 'Output'\n",
        "      ELSE NULL\n",
        "    END as category\n",
        "  FROM measurement m\n",
        "  JOIN visit_occurrence v\n",
        "    ON m.person_id = v.person_id\n",
        "    AND m.measurement_datetime >= v.visit_start_datetime\n",
        "    AND (v.visit_end_datetime IS NULL OR m.measurement_datetime <= v.visit_end_datetime)\n",
        "  WHERE m.measurement_concept_id IN ({all_ids_sql_list})\n",
        "  AND m.person_id IN (SELECT person_id FROM vlist)\n",
        "),\n",
        "daily_agg AS (\n",
        "  SELECT\n",
        "    person_id,\n",
        "    visit_occurrence_id,\n",
        "    report_date,\n",
        "    SUM(CASE WHEN category = 'Input' THEN value_as_number ELSE 0 END) as total_input,\n",
        "    SUM(CASE WHEN category = 'Output' THEN value_as_number ELSE 0 END) as total_output\n",
        "  FROM labeled_data\n",
        "  GROUP BY person_id, visit_occurrence_id, report_date\n",
        ")\n",
        "SELECT\n",
        "  person_id,\n",
        "  visit_occurrence_id,\n",
        "  report_date,\n",
        "  CAST(total_input AS INT64) as total_input,\n",
        "  CAST(total_output AS INT64) as total_output,\n",
        "  CAST((total_input - total_output) AS INT64) as daily_balance,\n",
        "  -- Calculate Cumulative Sum partitioned by Visit\n",
        "  CAST(SUM(total_input - total_output) OVER (\n",
        "    PARTITION BY person_id, visit_occurrence_id\n",
        "    ORDER BY report_date\n",
        "    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "  ) AS INT64) as cumulative_balance\n",
        "FROM daily_agg\n",
        "ORDER BY person_id, report_date\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing BigQuery extraction...\")\n",
        "fluid_balance = client.query(query_text, job_config=job_config).to_dataframe()\n",
        "\n",
        "# --- 5. Result Processing ---\n",
        "if fluid_balance.empty:\n",
        "    print(\"WARNING: No data returned for the specified criteria.\")\n",
        "else:\n",
        "    # Ensure correct datetime format\n",
        "    fluid_balance['report_date'] = pd.to_datetime(fluid_balance['report_date'])\n",
        "\n",
        "    print(f\"Extraction complete. Retrieved {len(fluid_balance)} records.\")\n",
        "    display(fluid_balance.head())"
      ],
      "metadata": {
        "id": "9xFTWn3e4f6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}